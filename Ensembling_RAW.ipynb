{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "183f254f-e67d-4951-b362-2dc57b997d98",
   "metadata": {},
   "source": [
    "<h1> Hyperparameters tuning & Ensembles </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58f10fad-4e6d-4c09-b83a-4c4b669a006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics \n",
    "import scikitplot as skplt\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a29769-a05a-478e-b4ba-b26c1bc76c6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3> Problem: Predict Diabetes From Medical Records </h3>\n",
    "    <h4> Dataset: </h4>\n",
    "    <li> diabetes.csv </li>\n",
    "    <h4> About the dataset:</h4>\n",
    "    <li> <a href=https://www.kaggle.com/datasets/mathchi/diabetes-data-set> https://www.kaggle.com/datasets/mathchi/diabetes-data-set</a>\n",
    "    <h4> Content: </h4>\n",
    "      <li> Pregnancies: Number of times pregnant </li>\n",
    "      <li> Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test </li>\n",
    "      <li> BloodPressure: Diastolic blood pressure (mm Hg) </li>\n",
    "      <li> SkinThickness: Triceps skin fold thickness (mm) </li>\n",
    "    <li> Insulin: 2-Hour serum insulin (mu U/ml) </li>\n",
    "<li> BMI: Body mass index (weight in kg/(height in m)^2)</li>\n",
    "<li> DiabetesPedigreeFunction: Diabetes pedigree function</li>\n",
    "<li> Age: Age (years)</li>\n",
    "<li> Outcome: Class variable (0 or 1)</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e61c3a-5d3a-476f-bbbd-37f682629aae",
   "metadata": {},
   "source": [
    "<h4> I. Load the dataset </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30725969-45f6-46d5-aa58-4b14e077b0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bp</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnant  glucose  bp  skin  insulin   bmi  pedigree  age  outcome\n",
       "0         6      148  72    35        0  33.6     0.627   50        1\n",
       "1         1       85  66    29        0  26.6     0.351   31        0\n",
       "2         8      183  64     0        0  23.3     0.672   32        1\n",
       "3         1       89  66    23       94  28.1     0.167   21        0\n",
       "4         0      137  40    35      168  43.1     2.288   33        1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'outcome']\n",
    "data=pd.read_csv(\"diabetes.csv\",names=col_names, header=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966fa521-8ccc-497b-8f1a-1723fcd56253",
   "metadata": {},
   "source": [
    "<h4> II. Quick exploration of the dataset </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7787cd64-1526-40aa-af21-36d05d463de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   pregnant  768 non-null    int64  \n",
      " 1   glucose   768 non-null    int64  \n",
      " 2   bp        768 non-null    int64  \n",
      " 3   skin      768 non-null    int64  \n",
      " 4   insulin   768 non-null    int64  \n",
      " 5   bmi       768 non-null    float64\n",
      " 6   pedigree  768 non-null    float64\n",
      " 7   age       768 non-null    int64  \n",
      " 8   outcome   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7df9dcaa-0c79-41ab-8b29-e4cc0fdc5b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bp</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pregnant     glucose          bp        skin     insulin         bmi  \\\n",
       "count  768.000000  768.000000  768.000000  768.000000  768.000000  768.000000   \n",
       "mean     3.845052  120.894531   69.105469   20.536458   79.799479   31.992578   \n",
       "std      3.369578   31.972618   19.355807   15.952218  115.244002    7.884160   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
       "50%      3.000000  117.000000   72.000000   23.000000   30.500000   32.000000   \n",
       "75%      6.000000  140.250000   80.000000   32.000000  127.250000   36.600000   \n",
       "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
       "\n",
       "         pedigree         age     outcome  \n",
       "count  768.000000  768.000000  768.000000  \n",
       "mean     0.471876   33.240885    0.348958  \n",
       "std      0.331329   11.760232    0.476951  \n",
       "min      0.078000   21.000000    0.000000  \n",
       "25%      0.243750   24.000000    0.000000  \n",
       "50%      0.372500   29.000000    0.000000  \n",
       "75%      0.626250   41.000000    1.000000  \n",
       "max      2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da0bad4-58f4-4902-ab2b-64d0d92f55c4",
   "metadata": {},
   "source": [
    "<b> For bmi, glucose, bp and skin the min value is 0 which is impossible. Missing values may have been filled with 0.\n",
    "We may want to replace all 0 values with NaN and use imputation techniques to impute the data </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ad8bfa2-ca10-429b-9a27-3c0cc0e21e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'outcome']\n",
    "columns = ['bmi', 'glucose', 'bp', 'skin']\n",
    "\n",
    "for col in columns:\n",
    "    data[col] = data[col].map(lambda x:x if x != 0 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8eca8c37-60ee-4d46-a54d-80c5ed5b2cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pregnant      0\n",
       "glucose       5\n",
       "bp           35\n",
       "skin        227\n",
       "insulin       0\n",
       "bmi          11\n",
       "pedigree      0\n",
       "age           0\n",
       "outcome       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7c8f8d5-cb53-4a3e-a258-d5f8bae43aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#data[data[\"glucose\"]==1]\n",
    "label, counts = np.unique(data.outcome, return_counts=True)\n",
    "plt.bar(label, counts)\n",
    "plt.title('Class Frequency')\n",
    "plt.xlabel('Class')\n",
    "plt.xticks(range(0,2,1))\n",
    "plt.ylabel('Frequency')\n",
    "#label, counts "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69676fe0-69eb-419e-b8aa-51bfec097d10",
   "metadata": {},
   "source": [
    "<h4> III. Train an ensemble for diabetes prediction</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b997f6-4c09-4b15-8b67-297a43193b4f",
   "metadata": {},
   "source": [
    "<h5> 1) Split it into training set, a validation set, and a test set : use\n",
    "30% of data for test, 30% of training for validation </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97d8f9ec-9336-42eb-a697-0c1ce42e5075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bp</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pregnant  glucose    bp  skin  insulin   bmi  pedigree  age\n",
       "0           6    148.0  72.0  35.0        0  33.6     0.627   50\n",
       "1           1     85.0  66.0  29.0        0  26.6     0.351   31\n",
       "2           8    183.0  64.0   NaN        0  23.3     0.672   32\n",
       "3           1     89.0  66.0  23.0       94  28.1     0.167   21\n",
       "4           0    137.0  40.0  35.0      168  43.1     2.288   33\n",
       "..        ...      ...   ...   ...      ...   ...       ...  ...\n",
       "763        10    101.0  76.0  48.0      180  32.9     0.171   63\n",
       "764         2    122.0  70.0  27.0        0  36.8     0.340   27\n",
       "765         5    121.0  72.0  23.0      112  26.2     0.245   30\n",
       "766         1    126.0  60.0   NaN        0  30.1     0.349   47\n",
       "767         1     93.0  70.0  31.0        0  30.4     0.315   23\n",
       "\n",
       "[768 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:,:-1] # Features\n",
    "y = data.outcome\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "X_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "X\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddaafd76-dc69-4977-b3a7-f01291ff14f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 614 , Val: 154 , Test: 231\n",
      "Train set: \n",
      "Positives:  0.35993485342019543\n",
      "Negatives:  0.6400651465798045\n",
      "Val set: \n",
      "Positives:  0.3051948051948052\n",
      "Negatives:  0.6948051948051948\n",
      "Test set: \n",
      "Positives:  0.3203463203463203\n",
      "Negatives:  0.6796536796536796\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\", len(X_train), \", Val:\", len(X_val),\", Test:\", len(X_test))\n",
    "\n",
    "print(\"Train set: \")\n",
    "print(\"Positives: \", len(y_train[y_train==1])/len(X_train))\n",
    "print(\"Negatives: \", len(y_train[y_train==0])/len(X_train))\n",
    "\n",
    "print(\"Val set: \")\n",
    "print(\"Positives: \", len(y_val[y_val==1])/len(X_val))\n",
    "print(\"Negatives: \", len(y_val[y_val==0])/len(X_val))\n",
    "\n",
    "print(\"Test set: \")\n",
    "print(\"Positives: \", len(y_test[y_test==1])/len(X_test))\n",
    "print(\"Negatives: \", len(y_test[y_test==0])/len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5d22c8-81f0-4bbc-867f-8b0535f04396",
   "metadata": {},
   "source": [
    "<b> 2) using sklearn pipeline, create a pipeline with the followins steps : <br/> </b>\n",
    " - Imputation to fill the missing values : you can use the SimpleImputer() method \n",
    " - Standardization for data normalization : you can use the MinMaxScaler() method\n",
    " - Classification for prediction : we will test three different models for prediction (SVM, Decision Tree and Logistic Regression) <br/>\n",
    "\n",
    "<b> 3) fit the pipline and print the scores of the different models</b> <br/>\n",
    " - As a first step, use the models with the default parameters\n",
    " - for the score: since we are dealing with an umbalanced dataset we may use f1_score\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036348e2",
   "metadata": {},
   "source": [
    "# imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f291a63-5cea-43cd-aea5-4e8315fe522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Remplacer les valeurs aberrantes par la médiane\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "data_imputed = imputer.fit_transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd14a439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbede0b",
   "metadata": {},
   "source": [
    "# normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80b8df51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9be06ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "354ba073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35294118, 0.67096774, 0.48979592, ..., 0.23441503, 0.48333333,\n",
       "        1.        ],\n",
       "       [0.05882353, 0.26451613, 0.42857143, ..., 0.11656704, 0.16666667,\n",
       "        0.        ],\n",
       "       [0.47058824, 0.89677419, 0.40816327, ..., 0.25362938, 0.18333333,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.29411765, 0.49677419, 0.48979592, ..., 0.07130658, 0.15      ,\n",
       "        0.        ],\n",
       "       [0.05882353, 0.52903226, 0.36734694, ..., 0.11571307, 0.43333333,\n",
       "        1.        ],\n",
       "       [0.05882353, 0.31612903, 0.46938776, ..., 0.10119556, 0.03333333,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_normalisation=scaler.fit_transform(data_imputed)\n",
    "data_normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55d7e868",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normalisation=pd.DataFrame(data_normalisation,columns=['pregnant','glucose','bp','skin','insulin','bmi','pedigree','age','outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64db2bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bp</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.314928</td>\n",
       "      <td>0.234415</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.264516</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.171779</td>\n",
       "      <td>0.116567</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.896774</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.104294</td>\n",
       "      <td>0.253629</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.202454</td>\n",
       "      <td>0.038002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.163265</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.198582</td>\n",
       "      <td>0.509202</td>\n",
       "      <td>0.943638</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.367742</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.445652</td>\n",
       "      <td>0.212766</td>\n",
       "      <td>0.300613</td>\n",
       "      <td>0.039710</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.503226</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380368</td>\n",
       "      <td>0.111870</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.496774</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.132388</td>\n",
       "      <td>0.163599</td>\n",
       "      <td>0.071307</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.529032</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.243354</td>\n",
       "      <td>0.115713</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.316129</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249489</td>\n",
       "      <td>0.101196</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pregnant   glucose        bp      skin   insulin       bmi  pedigree  \\\n",
       "0    0.352941  0.670968  0.489796  0.304348  0.000000  0.314928  0.234415   \n",
       "1    0.058824  0.264516  0.428571  0.239130  0.000000  0.171779  0.116567   \n",
       "2    0.470588  0.896774  0.408163  0.239130  0.000000  0.104294  0.253629   \n",
       "3    0.058824  0.290323  0.428571  0.173913  0.111111  0.202454  0.038002   \n",
       "4    0.000000  0.600000  0.163265  0.304348  0.198582  0.509202  0.943638   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "763  0.588235  0.367742  0.530612  0.445652  0.212766  0.300613  0.039710   \n",
       "764  0.117647  0.503226  0.469388  0.217391  0.000000  0.380368  0.111870   \n",
       "765  0.294118  0.496774  0.489796  0.173913  0.132388  0.163599  0.071307   \n",
       "766  0.058824  0.529032  0.367347  0.239130  0.000000  0.243354  0.115713   \n",
       "767  0.058824  0.316129  0.469388  0.260870  0.000000  0.249489  0.101196   \n",
       "\n",
       "          age  outcome  \n",
       "0    0.483333      1.0  \n",
       "1    0.166667      0.0  \n",
       "2    0.183333      1.0  \n",
       "3    0.000000      0.0  \n",
       "4    0.200000      1.0  \n",
       "..        ...      ...  \n",
       "763  0.700000      0.0  \n",
       "764  0.100000      0.0  \n",
       "765  0.150000      0.0  \n",
       "766  0.433333      1.0  \n",
       "767  0.033333      0.0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9753ad1",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66c78f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bp</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.423913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.488753</td>\n",
       "      <td>0.125107</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.251613</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.233134</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.503226</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380368</td>\n",
       "      <td>0.111870</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.551020</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.415133</td>\n",
       "      <td>0.188728</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.509677</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.370143</td>\n",
       "      <td>0.076857</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.367742</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.445652</td>\n",
       "      <td>0.212766</td>\n",
       "      <td>0.300613</td>\n",
       "      <td>0.039710</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249489</td>\n",
       "      <td>0.130231</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.418367</td>\n",
       "      <td>0.163043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132924</td>\n",
       "      <td>0.029889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.264516</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.243354</td>\n",
       "      <td>0.094791</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.593548</td>\n",
       "      <td>0.591837</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288344</td>\n",
       "      <td>0.239966</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>537 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pregnant   glucose        bp      skin   insulin       bmi  pedigree  \\\n",
       "580  0.000000  0.690323  0.673469  0.423913  0.000000  0.488753  0.125107   \n",
       "418  0.058824  0.251613  0.448980  0.239130  0.000000  0.000000  0.233134   \n",
       "764  0.117647  0.503226  0.469388  0.217391  0.000000  0.380368  0.111870   \n",
       "363  0.235294  0.658065  0.551020  0.239130  0.000000  0.415133  0.188728   \n",
       "757  0.000000  0.509677  0.489796  0.239130  0.000000  0.370143  0.076857   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "763  0.588235  0.367742  0.530612  0.445652  0.212766  0.300613  0.039710   \n",
       "192  0.411765  0.741935  0.428571  0.239130  0.000000  0.249489  0.130231   \n",
       "629  0.235294  0.322581  0.418367  0.163043  0.000000  0.132924  0.029889   \n",
       "559  0.647059  0.264516  0.510204  0.239130  0.000000  0.243354  0.094791   \n",
       "684  0.294118  0.593548  0.591837  0.239130  0.000000  0.288344  0.239966   \n",
       "\n",
       "          age  \n",
       "580  0.000000  \n",
       "418  0.100000  \n",
       "764  0.100000  \n",
       "363  0.766667  \n",
       "757  0.516667  \n",
       "..        ...  \n",
       "763  0.700000  \n",
       "192  0.250000  \n",
       "629  0.000000  \n",
       "559  0.233333  \n",
       "684  0.800000  \n",
       "\n",
       "[537 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data_normalisation.iloc[:,:-1] # Features\n",
    "y = data_normalisation.outcome\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c16db86",
   "metadata": {},
   "source": [
    "<h2 style=\"color:green;\">Pipline</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "488ff6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM: 0.7575757575757576\n",
      "Accuracy of Decision Tree: 0.7316017316017316\n",
      "Accuracy of Logistic Regression: 0.7705627705627706\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the steps in the pipeline\n",
    "steps = [\n",
    "    ('imputer', SimpleImputer()),  # Step 1: Imputation to fill missing values\n",
    "    ('scaler', MinMaxScaler()),    # Step 2: Standardization for data normalization\n",
    "    ('classifier', None)           # Step 3: Classifier (will be replaced by different models)\n",
    "]\n",
    "\n",
    "# Create an empty pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Define the three different models for classification\n",
    "svm_model = SVC()\n",
    "decision_tree_model = DecisionTreeClassifier()\n",
    "logistic_regression_model = LogisticRegression()\n",
    "\n",
    "# Create a list of tuples, each containing the model name and the corresponding model object\n",
    "models = [\n",
    "    ('SVM', svm_model),\n",
    "    ('Decision Tree', decision_tree_model),\n",
    "    ('Logistic Regression', logistic_regression_model)\n",
    "]\n",
    "\n",
    "# Iterate over each model and fit it into the pipeline\n",
    "for model_name, model_object in models:\n",
    "    pipeline.steps[-1] = ('classifier', model_object)  # Replace the classifier in the pipeline\n",
    "    pipeline.fit(X_train, y_train)  # Assuming X_train and y_train are your training data\n",
    "    accuracy = pipeline.score(X_test, y_test)  # Assuming X_test and y_test are your test data\n",
    "    print(f\"Accuracy of {model_name}: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba88f78-019c-41f0-9590-bef90e66ad6f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<h4> Tuning classification models</h4>\n",
    "<b> 4) Use GridSearchCV to test different values for the used models hyperparameters <br/> </b>\n",
    "\n",
    " - you can use <b>estimator.get_params().keys() </b> to find the parameters of an estimator\n",
    " - you can also test different strategies for imputation (e.g., \"mean\", \"median\", \"most_frequent\", \"constant\")\n",
    " - for each model, keep the best estimator\n",
    " - compare with the scores of default models\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe41f10f-b8f8-4e1b-a402-858f577ad44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning SVM...\n",
      "Tuning Decision Tree...\n",
      "Tuning Logistic Regression...\n",
      "Tuning Random Forest...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24660\\3520965191.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[0mdefault_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0my_pred_default\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefault_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m     \u001b[0mdefault_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_default\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# Tune model with different imputation strategies\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[0;32m     93\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "\n",
    "# Split the data\n",
    "\n",
    "\n",
    "# Define models and hyperparameter grids\n",
    "models = {\n",
    "    'SVM': SVC(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=10000),\n",
    "    'Random Forest': RandomForestRegressor()\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'SVM': {\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__gamma': ['scale', 'auto'],\n",
    "        'classifier__kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'classifier__criterion': ['gini', 'entropy'],\n",
    "        'classifier__max_depth': [None, 10, 20, 30],\n",
    "        'classifier__min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__solver': ['liblinear', 'lbfgs']\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'classifier__max_depth': [None, 10, 20, 30],\n",
    "        'classifier__min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "}\n",
    "\n",
    "imputation_strategies = ['mean', 'median', 'most_frequent', 'constant']\n",
    "\n",
    "# Function to create pipeline and perform GridSearchCV\n",
    "def tune_model(model_name, model, param_grid, impute_strategy):\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=impute_strategy)),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_score = grid_search.best_score_\n",
    "    \n",
    "    return best_model, best_score\n",
    "\n",
    "# Tuning models and comparing with default models\n",
    "best_models = {}\n",
    "default_scores = {}\n",
    "tuned_scores = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Tuning {model_name}...\")\n",
    "    \n",
    "    # Get default model score\n",
    "    default_model = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    default_model.fit(X_train, y_train)\n",
    "    y_pred_default = default_model.predict(X_test)\n",
    "    default_scores[model_name] = accuracy_score(y_test, y_pred_default)\n",
    "    \n",
    "    # Tune model with different imputation strategies\n",
    "    best_score = 0\n",
    "    for strategy in imputation_strategies:\n",
    "        tuned_model, score = tune_model(model_name, model, param_grids[model_name], strategy)\n",
    "        if score > best_score:\n",
    "            best_models[model_name] = tuned_model\n",
    "            best_score = score\n",
    "            tuned_scores[model_name] = best_score\n",
    "\n",
    "# Display results\n",
    "print(\"\\nDefault Model Scores:\")\n",
    "for model_name, score in default_scores.items():\n",
    "    print(f\"{model_name}: {score:.4f}\")\n",
    "\n",
    "print(\"\\nTuned Model Scores:\")\n",
    "for model_name, score in tuned_scores.items():\n",
    "    print(f\"{model_name}: {score:.4f}\")\n",
    "\n",
    "# Test the best models on the test set\n",
    "print(\"\\nTesting Best Models on Test Set:\")\n",
    "for model_name, model in best_models.items():\n",
    "    y_pred_tuned = model.predict(X_test)\n",
    "    test_score = accuracy_score(y_test, y_pred_tuned)\n",
    "    print(f\"{model_name}: {test_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b990e1-860f-4bc5-ae20-1cab5ead3d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2b7669-6912-42bb-8be3-f89d2defabc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6e2457b-01d8-409d-b34b-7b33f1098ad6",
   "metadata": {},
   "source": [
    "<h4> Ensembling </h4>\n",
    "<b> 5) using the best estimators, train a voting ensemble <br/> </b>\n",
    "\n",
    "- use VotingClassifier from sklearn.ensemble \n",
    "- test different voting strategies (hard vs soft) and different weight combination\n",
    "- compare the scores of the ensembles with that of weak learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c08cdae-f085-4c8f-b94b-1ff78d9edbff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627855b0-1c5e-445e-bb51-552ba339f52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28026209-6a7d-42c3-9d3e-67cd3383e1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d0d4cd3-1515-4a07-8e8d-b2e65d54bdc6",
   "metadata": {},
   "source": [
    "<b> 6) Implement and train a stacking ensemble </b> <br/>\n",
    " - use the training set to train the level 0 learner and the validation set to train the meta-learner\n",
    " - use StratifiedKFold for cross validation : \n",
    " \n",
    "     - for each fold, level 0 learner will be fit to the train set and used for prediction on the validation set\n",
    "     \n",
    "     - fold predictions are stored in a new dataset\n",
    " \n",
    " - Use the new dataset for training a voting, a logistic regression model,....\n",
    " - compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "3d2e4ffc-f5c9-4cf3-9e98-b336d0df674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b073ee4-2839-4524-8478-1b3ee13d3ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e994c86a-96ab-4bcb-86e2-77052a1ddc44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9b6d86-d269-4450-ab78-3ad5fa66a646",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0efeee-f6cd-44e2-9012-b3018cbc78cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e738fe7b-b7fe-4875-b3b9-dc87f67f568f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2694ea71-e61d-4c4e-bc5b-25151e153cbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
